{
 "cells": [
  {
   "cell_type": "raw",
   "id": "bb61d9e1-79fa-4e8a-87ac-e0a87285e1a4",
   "metadata": {},
   "source": [
    "---\n",
    "title: Access NASA Data with earthaccess üåç\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56ba2387-54e8-4aa5-aedb-c7d90644536f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Access NASA Data with *earthaccess*\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/717735/205517116-7a5d0f41-7acc-441e-94ba-2e541bfb7fc8.png\"  width=\"400\">\n",
    "\n",
    "## Why?\n",
    "\n",
    "**Programmatic, Easy, Reproducible.**\n",
    "\n",
    "There are many ways to access NASA datasets. We can use [Earthdata Search](https://search.earthaccess.nasa.gov/). We can use [DAAC](https://www.earthdata.nasa.gov/eosdis/daacs)-specific portals or tools. We could even use [data.gov](https://data.gov)! Web portals are great but they are not designed for programmatic access and reproducible workflows. This is extremely important in the age of the cloud and open science.  \n",
    "\n",
    "The good news is that NASA exposes APIs allowing us to search, transform, and access data programmatically. Many of these libraries contain amazing features and some similarities. In this context, *earthaccess* aims to be a simple library that can deal with the important parts of the metadata so we can access or download data without having to worry if a given dataset is on-prem or in the cloud.  \n",
    "\n",
    "<!-- > Note: There are a lot of acronyms, abbreviations, and jargon to get familiar with before any of this makes sense. This brief glossary of [NASA Earthdata terms](glossary.md) can help.  -->\n",
    "\n",
    "### What?\n",
    "\n",
    "[*earthaccess*](https://github.com/nsidc/earthaccess) is a Python library to search, preview and access NASA Earth science datasets (on-prem or in the cloud) with a few lines of code.  \n",
    "\n",
    "## How?\n",
    "\n",
    "1. To begin the tutorial, we must first register for an [Earthdata Login](https://urs.earthaccess.nasa.gov/) (EDL) profile, which provides free and immediate access to thousands of NASA's Earth Observing System Data and Information System (EOSDIS) data products covering all Earth science disciplines and topic areas for researchers, applied science users, application developers, and the general public.  \n",
    "2. Next, we install *earthaccess* by following the documentation for [installing earthaccess](https://github.com/nsidc/earthaccess#installing-earthaccess).  \n",
    "3. Then we use *earthaccess* to authenticate our EDL profile by following one of the three [authentication](https://github.com/nsidc/earthaccess#authentication) methods.  \n",
    "\n",
    "Now we can start accessing NASA data programmatically!  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fcc8b461-8c68-4719-94e5-34057159dac7",
   "metadata": {},
   "source": [
    "## Querying for Aatasets\n",
    "\n",
    "The `DataCollections` class can query CMR for any collection (dataset) using all of CMR's Query parameters and has built-in functions to extract useful information from the response.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5bf4c9-571b-4c93-af94-e66bd51cb584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataCollections query \n",
    "Query = DataCollections()\n",
    "\n",
    "# Use chain methods to customize the query and print the results\n",
    "Query.keyword('elevation').bounding_box(-134.7,58.9,-133.9,59.2).temporal(\"2020-01-01\",\"2020-02-01\")\n",
    "print(f'Collections found: {Query.hits()}')\n",
    "\n",
    "# Filter what fields to print; omit Query.fields arguments to see the full record\n",
    "collections = Query.fields(['ShortName','Version']).get(5)\n",
    "\n",
    "# Inspect results by printing just first three records\n",
    "collections[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26962664-cbe8-453f-b617-80d473df9c75",
   "metadata": {},
   "source": [
    "The results from a DataCollections and DataGranules query are enhanced python dictionaries, this means\n",
    "that we can access all the keys and values like we usually do with Python dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb5154c-f131-44ad-a68f-cf0fa21ce18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "collections[0][\"umm\"][\"ShortName\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d45a6f-ac37-4744-bcfe-88ac3dd6ac07",
   "metadata": {},
   "source": [
    "The DataCollections class returns python dictionaries with some handy methods.\n",
    "\n",
    "```python \n",
    "collection.concept_id() # returns the concept-id, used to search for data granules\n",
    "collection.abstract() # returns the abstract\n",
    "collection.landing_page() # returns the landing page if present in the UMM fields\n",
    "collection.get_data() # returns the portal where data can be accessed.\n",
    "```\n",
    "\n",
    "The same results can be obtained using the `dict` syntax:\n",
    "\n",
    "```python\n",
    "collection[\"meta\"][\"concept-id\"] # concept-id\n",
    "collection[\"umm\"][\"RelatedUrls\"] # URLs, with GET DATA, LANDING PAGE etc\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cdcd74-dfe3-4b83-93f4-7378a0d981df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for collections using a pythonic API client for CMR\n",
    "Query = DataCollections().daac(\"PODAAC\")\n",
    "print(f'Collections found: {Query.hits()}')\n",
    "\n",
    "collections = Query.fields(['ShortName']).get(10)\n",
    "collections[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63792353-ab3e-4f0b-963d-7750e4b89113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for collections using a pythonic API client for CMR\n",
    "Query = DataCollections().daac(\"PODAAC\")\n",
    "print(f'Collections found: {Query.hits()}')\n",
    "\n",
    "collections = Query.fields(['ShortName']).get(10)\n",
    "collections[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c5a34a-e808-4cc9-b34d-353d091a8242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the concept-id for the first 10 collections\n",
    "[collection.concept_id() for collection in collections]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb9c3bb-ac8b-48e8-8233-8c44da8fb7bc",
   "metadata": {},
   "source": [
    "## Querying for data files (granules)\n",
    "\n",
    "The DataGranules class provides similar functionality as the collection class. To query for granules in a more reliable way concept-id would be the main key.\n",
    "You can search data granules using a short name but that could (more likely will) return different versions of the same data granules. \n",
    "\n",
    "In this example we're querying for 10 data grnaules from ICESat-2  [ATL06](https://nsidc.org/data/ATL06/versions/) version `005` dataset. \n",
    "\n",
    "\n",
    "> **Note**: Generally speaking we won't need authenticated queries unless they are restricted datasets for early adopters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9364d737-5a79-4089-853f-76d2ad1c85a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We build our query\n",
    "from pprint import pprint\n",
    "Query = DataGranules().short_name('ATL06').version(\"005\").bounding_box(-134.7,58.9,-133.9,59.2)\n",
    "# We get 5 metadata records\n",
    "granules = Query.get(5)\n",
    "granules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aa8035-f4a8-4592-b19c-49d5c06331fb",
   "metadata": {},
   "source": [
    "## Pretty printing data granules\n",
    "\n",
    "Since we are in a notebook we can take advantage of it to see a more user friendly version of the granules with the built-in function `display`\n",
    "This will render browse image for the granule if available and eventually will have a similar representation as the one from the Earthdata search portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cd5f5c-a854-4a72-a831-33b8bd7ce9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing 2 granules using display\n",
    "[display(granule) for granule in granules]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8f32a4-026d-4a5f-af66-69026cabe966",
   "metadata": {},
   "source": [
    "### Spatiotemporal queries\n",
    "\n",
    "Our granules and collection classes accept the same spatial and temporal arguments as CMR so we can search for granules that match spatiotemporal criteria.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aa39ec-e2fb-49d1-bc54-8d8a2f0655aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Query = DataGranules().short_name(\"ATL06\").temporal(\"2020-03-01\", \"2020-03-30\").bounding_box(-134.7,58.9,-133.9,59.2).version(\"005\")\n",
    "# Always inspects the hits before retrieven the granule metadata, just because it's very verbose.\n",
    "print(f\"Granules found: {Query.hits()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c493585-0d48-41bb-8815-6c83ad20ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can print some info about these granules using the built-in methods\n",
    "granules = Query.get(5)\n",
    "data_links = [{'links': g.data_links(access=\"on_prem\"), 'size (MB):': g.size()} for g in granules]\n",
    "data_links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c90c43-6e17-42f5-8bf5-95fdd3cb0dce",
   "metadata": {},
   "source": [
    "## **Accessing the data**\n",
    "\n",
    "With `earthaccess` a researcher can get the files regardless if they are on-prem or cloud based with the same API call, although an important consideration is that if we want to access data in the cloud (direct access) we must run the code in the cloud. This is because some S3 buckets are configured to only allow direct access (s3:// links) if the requester is in the same zone, `us-west-2`.\n",
    "\n",
    "## On-prem access: DAAC hosted data  üì°\n",
    "\n",
    "\n",
    "\n",
    "The `Store()` class will allow us to download or access our data and needs to be instantiated with our `auth` instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b796fa53-60ac-4197-922d-1f6ee5dec00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = Store(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4239e041-db87-40d1-b81a-12c26e9e0a47",
   "metadata": {},
   "source": [
    "For this example we are going to use a PODAAC dataset `SMAP_JPL_L3_SSS_CAP_8DAY-RUNNINGMEAN_V5` which we previously queried (see querying for datasets) and got the concept id: `C1972955240-PODAAC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910e4b90-f0e0-42e5-a4e2-d5444089161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Query = DataGranules().concept_id(\"C1972955240-PODAAC\").bounding_box(-134.7,54.9,-100.9,69.2)\n",
    "print(f\"Granule hits: {Query.hits()}\")\n",
    "# getting more than 6,000 metadata records for demo purposes is going to slow us down a bit so let's get only a few\n",
    "granules = Query.get(10)\n",
    "# Does this granule belong to a cloud-based collection?\n",
    "granules[0].cloud_hosted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436e8a72-64c5-4e6b-950b-ac801d7b926e",
   "metadata": {},
   "source": [
    "### Finally! let's get the data\n",
    "\n",
    "The Store class accepts the results from a `DataGranules()` query or it can also accept a list of URLs for the data files. In the second case we'll have to specify the DAAC since it cannot infer which credentials to use solely on the URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434466a3-602b-4dff-a260-f7db6901514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "files = store.get(granules[0:4], \"./data/C1972955240-PODAAC/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe45fff-68ea-4f01-94c7-416d79cfd84c",
   "metadata": {},
   "source": [
    "## **Accessing the data in the cloud ‚òÅÔ∏è** \n",
    "<img src=\"https://www.freecodecamp.org/news/content/images/size/w2000/2020/08/Screenshot-2020-08-10-at-6.26.31-PM.png\" width=\"300px\" align=\"middle\" >\n",
    "\n",
    "\n",
    "\n",
    "With `earthaccess` a researcher can get the files regardless if they are on-prem or cloud based with the same API call, although an important consideration is that if we want to access data in the cloud we must run the code in the cloud. This is because some S3 buckets are configured to only allow direct access (s3:// links) if the requester is in the same zone, `us-west-2`.\n",
    "\n",
    "Same API, just a different place, in this case the `concept-id` for the same dataset is `C2208422957-POCLOUD`\n",
    "> Note: The `concept-id` changed even though is the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44403d51-0aa3-423c-8fff-e40d4969aa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Query = DataGranules().concept_id(\"C2208422957-POCLOUD\").bounding_box(-134.7,54.9,-100.9,69.2)\n",
    "print(f\"Granule hits: {Query.hits()}\")\n",
    "cloud_granules = Query.get(10)\n",
    "# is this a cloud hosted data granule?\n",
    "cloud_granules[0].cloud_hosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e59ca3e-b5d5-490f-b967-01d1c7b3fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pretty print this\n",
    "cloud_granules[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a294f1-b1f9-4cd4-8751-dfc32feacec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# If we get an error with direct_access=True, most likely is because\n",
    "# we are running this code outside the us-west-2 region.\n",
    "try:\n",
    "    files = store.get(cloud_granules[0:4], local_path=\"./data/demo-POCLOUD\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}, we are probably not using this code in the Amazon cloud. Trying external links...\")\n",
    "    # There is hope, even if we are not in the Amazon cloud we can still get the data\n",
    "    files = store.get(cloud_granules[0:4], access=\"external\", local_path=\"./data/demo-POCLOUD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b91b45-7080-4257-8ccb-99f87c93b022",
   "metadata": {},
   "source": [
    "##  ‚òÅÔ∏è **Cloud Access Part II: streaming data**\n",
    "\n",
    "Being in the cloud allows us to stream data as if we were using it locally. Pairing gridded datasets on S3 and xarray isa very useful patter when we deal with a lot of data. \n",
    "\n",
    "> **Recommended read: [Skip the download! Stream NASA data directly into Python objects](https://medium.com/pangeo/intake-stac-nasa-4cd78d6246b7)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecdb529-5961-4fa6-b7e0-70bbd0d85041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "import xarray as xr\n",
    "# data_links\n",
    "https_links = []\n",
    "s3_links = []\n",
    "\n",
    "fs = store.get_s3fs_session('POCLOUD')\n",
    "\n",
    "for granule in cloud_granules:\n",
    "    https_links.extend(granule.data_links(access=\"on_prem\"))\n",
    "    s3_links.extend(granule.data_links(access=\"direct\"))\n",
    "s3_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e693af6a-a80e-4ca2-a034-8da194c18aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "try:\n",
    "    files = store.open(s3_links, provider=\"POCLOUD\")\n",
    "\n",
    "    ds_L3 = xr.open_mfdataset(\n",
    "        files,\n",
    "        combine='nested',\n",
    "        concat_dim='time',\n",
    "        decode_cf=True,\n",
    "        coords='minimal',\n",
    "        chunks={'time': 1}\n",
    "        )\n",
    "    ds_L3\n",
    "except Exception as e:\n",
    "    pass\n",
    "    # print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d276eca3-ca27-4970-9367-7e65e5f2302f",
   "metadata": {},
   "source": [
    "## Now to the important science! üöÄ \n",
    "\n",
    "### Recap\n",
    "\n",
    "```python\n",
    "\n",
    "from earthaccess import Auth, DataGranules, Store\n",
    "\n",
    "# first we authenticate with NASA EDL\n",
    "auth = Auth().login(strategy=\"netrc\")\n",
    "\n",
    "# Then we build a Query with spatiotemporal parameters\n",
    "GranuleQuery = DataGranules().concept_id(\"C1575731655-LPDAAC_ECS\").bounding_box(-134.7,58.9,-133.9,59.2)\n",
    "\n",
    "# We get the metadata records from CMR\n",
    "granules = GranuleQuery.get()\n",
    "\n",
    "# Now it{s time to download (or open) our data granules list with get()\n",
    "files = Store(auth).get(granules, local_path='./data')\n",
    "\n",
    "# Now to the important science!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d779e877-2f0c-4da2-92d5-6cc299204956",
   "metadata": {},
   "source": [
    "### Related links\n",
    "\n",
    "**Github repository**: https://github.com/nsidc/earthaccess\n",
    "\n",
    "**CMR** API documentation: https://cmr.earthaccess.nasa.gov/search/site/docs/search/api.html\n",
    "\n",
    "**EDL** API documentation: https://urs.earthaccess.nasa.gov/\n",
    "\n",
    "NASA OpenScapes: https://nasa-openscapes.github.io/earthaccess-cloud-cookbook/\n",
    "\n",
    "NSIDC: https://nsidc.org\n",
    "\n",
    "\n",
    "Contact: luis.lopez@nsidc.org"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
